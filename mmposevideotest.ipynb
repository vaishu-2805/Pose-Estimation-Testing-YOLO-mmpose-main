{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/02 12:17:16 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The current default scope \"mmdet\" is not \"mmpose\", `init_default_scope` will force set the currentdefault scope to \"mmpose\".\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-m_simcc-body7_pt-body7_420e-256x192-e48f03d0_20230504.pth\n",
      "10/02 12:17:16 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The current default scope \"mmpose\" is not \"mmdet\", `init_default_scope` will force set the currentdefault scope to \"mmdet\".\n",
      "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmdet_m_8xb32-100e_coco-obj365-person-235e8209.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pawel\\miniconda3\\envs\\openmmlab\\lib\\site-packages\\mmdet\\models\\layers\\se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "c:\\Users\\pawel\\miniconda3\\envs\\openmmlab\\lib\\site-packages\\mmdet\\models\\backbones\\csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n"
     ]
    }
   ],
   "source": [
    "import mmpose\n",
    "from mmpose.apis import MMPoseInferencer\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# video_path = \"./video/Kamera1.dav \"\n",
    "# video_path = \"./InputVideos/3255107-uhd_3840_2160_25fps.mp4\"\n",
    "video_path = \"./InputVideos/855565-hd_1920_1080_24fps.mp4\"\n",
    "video_capture = cv2.VideoCapture(video_path)\n",
    "\n",
    "#get video size\n",
    "w, h, = (\n",
    "\n",
    "    int(video_capture.get(x))\n",
    "\n",
    "    for x in (\n",
    "\n",
    "        cv2.CAP_PROP_FRAME_WIDTH,\n",
    "\n",
    "        cv2.CAP_PROP_FRAME_HEIGHT,\n",
    "\n",
    "    )\n",
    "\n",
    ")\n",
    "#create result file\n",
    "output_folder = \"./ResultsVideo\"\n",
    "res_path = os.path.basename(video_path)\n",
    "result = cv2.VideoWriter(os.path.join(output_folder, res_path), cv2.VideoWriter_fourcc(*\"mp4v\"), 10, (w, h)) #fps, (2 * w, 2 * h) mp4v MJPG\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "if not video_capture.isOpened():\n",
    "\n",
    "    raise ValueError(f\"Could not open video file: {video_path}\")\n",
    "\n",
    "#Do you want to skip frames?\n",
    "skip = False\n",
    "\n",
    "#skip frames at start where there is no people to detect (fps * time to skip[s])\n",
    "if skip:\n",
    "    skip_frames = 200\n",
    "\n",
    "    for _ in range(skip_frames):\n",
    "\n",
    "        ret, frame = video_capture.read()\n",
    "\n",
    "\n",
    "inferencer = MMPoseInferencer('human')\n",
    "\n",
    "ret = True\n",
    "\n",
    "# licz = 0\n",
    "\n",
    "while ret:\n",
    "    ret, frame = video_capture.read()\n",
    " \n",
    "    if not ret:\n",
    "         break\n",
    "\n",
    "\n",
    "    \n",
    "    result_generator = inferencer(frame, show=False,return_vis = True)  # turn off showing the result for speed\n",
    "    result_frame = next(result_generator)\n",
    "    nb_detected = len(result_frame['predictions'][0])\n",
    "    res = result_frame['visualization']\n",
    "    res = np.array(res[0])\n",
    "    \n",
    "    res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #show counter of detected people\n",
    "    text = f'Human detected: {nb_detected}'\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "    color = (0, 255, 0) \n",
    "    thickness = 2\n",
    "    position = (50, 50)  \n",
    "\n",
    "    \n",
    "    cv2.putText(res, text, position, font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "    result.write(res)\n",
    "    # licz += 1\n",
    "\n",
    "video_capture.release()\n",
    "result.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
